{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Audio\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(dir):\n",
    "    return [os.path.join(dir,x) for x in os.listdir(dir) if os.path.isfile(os.path.join(dir, x))]\n",
    "\n",
    "files = find_files(\"data/waves_yesno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1000])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(39, -0.648193359375),\n",
       " (53, 0.966796875),\n",
       " (53, 0.966796875),\n",
       " (104, -0.9051513671875),\n",
       " (104, -0.9051513671875),\n",
       " (104, -0.9051513671875),\n",
       " (118, 1.31011962890625),\n",
       " (118, 1.31011962890625),\n",
       " (168, -1.84478759765625),\n",
       " (168, -1.84478759765625),\n",
       " (168, -1.84478759765625),\n",
       " (168, -1.84478759765625),\n",
       " (178, 1.91741943359375),\n",
       " (178, 1.91741943359375),\n",
       " (178, 1.91741943359375),\n",
       " (178, 1.91741943359375),\n",
       " (226, -1.46392822265625),\n",
       " (226, -1.46392822265625),\n",
       " (239, 1.43524169921875),\n",
       " (239, 1.43524169921875),\n",
       " (239, 1.43524169921875),\n",
       " (282, -0.94512939453125),\n",
       " (343, -1.25518798828125),\n",
       " (343, -1.25518798828125),\n",
       " (343, -1.25518798828125),\n",
       " (361, 1.47003173828125),\n",
       " (378, 1.640625),\n",
       " (378, 1.640625),\n",
       " (414, -1.5948486328125),\n",
       " (414, -1.5948486328125),\n",
       " (423, 2.0025634765625),\n",
       " (423, 2.0025634765625),\n",
       " (423, 2.0025634765625),\n",
       " (423, 2.0025634765625),\n",
       " (476, -1.59820556640625),\n",
       " (485, 1.990966796875),\n",
       " (508, -1.619873046875),\n",
       " (508, -1.619873046875),\n",
       " (538, -2.08831787109375),\n",
       " (538, -2.08831787109375),\n",
       " (546, 2.00653076171875),\n",
       " (546, 2.00653076171875),\n",
       " (599, -2.55279541015625),\n",
       " (599, -2.55279541015625),\n",
       " (599, -2.55279541015625),\n",
       " (599, -2.55279541015625),\n",
       " (608, 2.11395263671875),\n",
       " (622, 2.373046875),\n",
       " (622, 2.373046875),\n",
       " (661, -2.41485595703125),\n",
       " (684, 2.3974609375),\n",
       " (684, 2.3974609375),\n",
       " (722, -2.6776123046875),\n",
       " (722, -2.6776123046875),\n",
       " (730, 2.626953125),\n",
       " (745, 2.7105712890625),\n",
       " (745, 2.7105712890625),\n",
       " (784, -2.9150390625),\n",
       " (784, -2.9150390625),\n",
       " (784, -2.9150390625),\n",
       " (784, -2.9150390625),\n",
       " (807, 2.7520751953125),\n",
       " (807, 2.7520751953125),\n",
       " (807, 2.7520751953125),\n",
       " (807, 2.7520751953125),\n",
       " (845, -2.86590576171875),\n",
       " (845, -2.86590576171875),\n",
       " (845, -2.86590576171875),\n",
       " (853, 2.7276611328125),\n",
       " (906, -2.56103515625),\n",
       " (914, 2.86346435546875),\n",
       " (914, 2.86346435546875),\n",
       " (914, 2.86346435546875),\n",
       " (914, 2.86346435546875),\n",
       " (967, -2.66265869140625),\n",
       " (967, -2.66265869140625)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sig, sr = torchaudio.load(files[2])\n",
    "sig = torchaudio.transforms.Scale()(sig)\n",
    "\n",
    "X = sig[7900:8900].transpose(0, 1) * 10\n",
    "X.unsqueeze_(0)\n",
    "#X.unsqueeze_(0)\n",
    "display(X.size())\n",
    "\n",
    "x_max, idx_max = torch.nn.functional.max_pool1d(X, 100, 25, 13, return_indices=True)\n",
    "x_min, idx_min = torch.nn.functional.max_pool1d(-X, 100, 25, 13, return_indices=True)\n",
    "x_max.squeeze(), idx_max.data.numpy(), -x_min.squeeze(), idx_min.data.numpy()\n",
    "max_list = list(zip(idx_max.data.squeeze().numpy(), x_max.data.squeeze()))\n",
    "min_list = list(zip(idx_min.data.squeeze().numpy(), -x_min.data.squeeze()))\n",
    "combined_list = sorted(max_list + min_list)\n",
    "display(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -0.0624 -0.0716 -0.0797 -0.0856 -0.0905 -0.0900 -0.0818 -0.0692 -0.0501\n",
       "\n",
       "Columns 9 to 17 \n",
       "  -0.0287 -0.0072  0.0182  0.0451  0.0731  0.0965  0.1147  0.1244  0.1286\n",
       "\n",
       "Columns 18 to 26 \n",
       "   0.1310  0.1280  0.1182  0.1014  0.0768  0.0516  0.0299  0.0112 -0.0106\n",
       "\n",
       "Columns 27 to 35 \n",
       "  -0.0326 -0.0532 -0.0644 -0.0667 -0.0625 -0.0581 -0.0517 -0.0411 -0.0269\n",
       "\n",
       "Columns 36 to 44 \n",
       "  -0.0071  0.0119  0.0245  0.0345  0.0388  0.0443  0.0449  0.0386  0.0284\n",
       "\n",
       "Columns 45 to 53 \n",
       "   0.0139  0.0010 -0.0069 -0.0127 -0.0211 -0.0263 -0.0274 -0.0225 -0.0141\n",
       "\n",
       "Columns 54 to 62 \n",
       "  -0.0041  0.0028  0.0041  0.0074  0.0062 -0.0039 -0.0194 -0.0416 -0.0692\n",
       "\n",
       "Columns 63 to 71 \n",
       "  -0.0992 -0.1273 -0.1520 -0.1707 -0.1809 -0.1845 -0.1731 -0.1436 -0.0975\n",
       "\n",
       "Columns 72 to 80 \n",
       "  -0.0462  0.0043  0.0543  0.1037  0.1487  0.1815  0.1917  0.1761  0.1512\n",
       "\n",
       "Columns 81 to 89 \n",
       "   0.1140  0.0734  0.0276 -0.0191 -0.0643 -0.0964 -0.1084 -0.1012 -0.0851\n",
       "\n",
       "Columns 90 to 98 \n",
       "  -0.0621 -0.0371 -0.0034  0.0344  0.0718  0.0935  0.0977  0.0902  0.0768\n",
       "\n",
       "Columns 99 to 99 \n",
       "   0.0605\n",
       "[torch.FloatTensor of size 1x1x100]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d(1, 3, kernel_size=(10,), stride=(9,), dilation=(2,), bias=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -0.0624 -0.0287  0.1310 -0.0326 -0.0071  0.0139 -0.0041 -0.0992 -0.0462\n",
       " -0.0210 -0.0097  0.0441 -0.0110 -0.0024  0.0047 -0.0014 -0.0334 -0.0156\n",
       " -0.0180 -0.0083  0.0378 -0.0094 -0.0020  0.0040 -0.0012 -0.0286 -0.0133\n",
       "\n",
       "Columns 9 to 11 \n",
       "   0.1140 -0.0621  0.0605\n",
       "  0.0384 -0.0209  0.0204\n",
       "  0.0329 -0.0179  0.0175\n",
       "[torch.FloatTensor of size 1x3x12]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = sig[8000:8100].transpose(0,1).unsqueeze(0)\n",
    "display(X2)\n",
    "conv_op = nn.Conv1d(1, 3, kernel_size=10, dilation=2, stride=9, bias=False)\n",
    "conv_op.weight = nn.Parameter(torch.cat((torch.ones(1, 1, 1), torch.rand(2, 1, 1))))\n",
    "print(conv_op)\n",
    "X2_conv = conv_op(Variable(X2))\n",
    "X2_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   0   1   2   3   4   5   6   7   8   9\n",
       "[torch.FloatTensor of size 1x1x10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "   2   3   5   7   9  11  13  15   7\n",
       "[torch.FloatTensor of size 1x1x9]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "   0   1   2   4   6   8  10  12  14  16   8   9\n",
       "[torch.FloatTensor of size 1x1x12]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convolutions\n",
    "X = torch.arange(0, 10).view(1, 1, -1)\n",
    "display(X)\n",
    "conv_op = nn.Conv1d(1, 1, 2, dilation=3, padding=1, bias=False)\n",
    "conv_op.weight = nn.Parameter(torch.ones(conv_op.weight.size()))\n",
    "display(conv_op(Variable(X)))\n",
    "tconv_op = nn.ConvTranspose1d(1, 1, 2, dilation=2, bias=False)\n",
    "tconv_op.weight = nn.Parameter(torch.ones(tconv_op.weight.size()))\n",
    "display(tconv_op(Variable(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.0000  1.0000  2.0000  3.0000  4.0000  5.0000  6.0000  7.0000  8.0000\n",
       "\n",
       "Columns 9 to 9 \n",
       "   9.0000\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "   0.1731  0.8068  0.1422  0.7546  0.9261  0.5195  0.4176  0.6777  0.1002\n",
       "\n",
       "Columns 9 to 9 \n",
       "   0.1254\n",
       "[torch.FloatTensor of size 2x1x10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  1.0000  3.0000  5.0000  7.0000  9.0000\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.8068  0.7546  0.9261  0.6777  0.1254\n",
       "[torch.FloatTensor of size 2x1x5]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pooling\n",
    "X = torch.cat((torch.arange(0, 10).view(1, 1, -1), torch.rand(1, 1, 10)))\n",
    "display(X)\n",
    "pool_op = nn.AdaptiveMaxPool1d(5)\n",
    "pool_op(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "   1   0   1   2   3   4   5   6   7   8   9   8\n",
       "[torch.FloatTensor of size 1x1x1x12]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Padding\n",
    "X = torch.arange(0, 10).view(1, 1, 1, -1)\n",
    "nn.ReflectionPad2d((1, 1, 0, 0))(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
