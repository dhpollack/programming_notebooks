{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import bs4\n",
    "import random\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "random.seed(12345)\n",
    "\n",
    "nltk.data.path.append(\"/home/david/Programming/data/nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_contractions(tokens):\n",
    "    contractions = set([\"'ve\", \"'d\", \"'m\", \"'ll\", \"'re\", \"n't\"])\n",
    "    return [\"\".join(tokens[i]) if (i+1 == len(tokens) or tokens[i+1] not in contractions) else \"\".join(tokens[(i):(i+2)]) for i in range(len(tokens)) if tokens[i] not in contractions]\n",
    "\n",
    "def data_processing(ds_paths, max_len=500, split_ratio=1.0):\n",
    "    ds = []\n",
    "    for i, tfp in enumerate(ds_paths):\n",
    "        idx, rating = os.path.basename(tfp).split(\".\")[0].split(\"_\")\n",
    "        with open(tfp, \"r\") as f:\n",
    "            raw = f.readlines()\n",
    "            raw = bs4.BeautifulSoup(raw[0], \"html5lib\")\n",
    "            txt = raw.get_text(separator=' ')\n",
    "            tokens = nltk.word_tokenize(txt)\n",
    "            tokens = concat_contractions(tokens)\n",
    "            #tokens = [vocab[w] if w in vocab else len(vocab) for w in tokens] # keep out of vocab\n",
    "            tokens = [vocab[w] for w in tokens if w in vocab]\n",
    "            if len(tokens) > max_len:\n",
    "                tokens = tokens[:max_len]\n",
    "            elif len(tokens) < max_len:\n",
    "                tokens = tokens + [0]*(max_len-len(tokens))\n",
    "            ds.append((tokens, int(rating)))\n",
    "    dat, labels = zip(*ds)\n",
    "    assert split_ratio >= 0. and split_ratio <= 1.0\n",
    "    if split_ratio == 1.:\n",
    "        return (dat, labels), (None, None)\n",
    "    else:\n",
    "        split_idx = int(len(dat) * split_ratio)\n",
    "        tidx = list(range(len(dat)))\n",
    "        random.shuffle(tidx)\n",
    "        tidx, vidx = tidx[:split_idx], tidx[split_idx:]\n",
    "        ts, ts_labels = [dat[tid] for tid in tidx], [labels[tid] for tid in tidx]\n",
    "        vs, vs_labels = [dat[vid] for vid in vidx], [labels[vid] for vid in vidx]\n",
    "        return (ts, ts_labels), (vs, vs_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdbEr.txt  imdb.vocab  README  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/david/Programming/data/aclImdb/train/neg/0_3.txt',\n",
       " '/home/david/Programming/data/aclImdb/train/neg/10000_4.txt',\n",
       " '/home/david/Programming/data/aclImdb/train/neg/10001_4.txt',\n",
       " '/home/david/Programming/data/aclImdb/train/neg/10002_1.txt',\n",
       " '/home/david/Programming/data/aclImdb/train/neg/10003_1.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_BASEDIR = \"/home/david/Programming/data/aclImdb\"\n",
    "%ls $IMDB_BASEDIR\n",
    "train_paths = sorted([f.path for d in [\"pos\", \"neg\"] for f in os.scandir(os.path.join(IMDB_BASEDIR, \"train\", d))])\n",
    "test_paths = sorted([f.path for d in [\"pos\", \"neg\"] for f in os.scandir(os.path.join(IMDB_BASEDIR, \"test\", d))])\n",
    "\n",
    "train_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_limit = 5000\n",
    "with open(os.path.join(IMDB_BASEDIR, \"imdb.vocab\"), \"r\") as f:\n",
    "    vocab = {w:(i+1) for i, w in enumerate([l.strip() for l in f.readlines()][:vocab_limit])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainset, validset = data_processing(train_paths, split_ratio = 0.9)\n",
    "print(len(trainset[0][0]), len(validset[0][0]))\n",
    "ts, ts_labels = torch.Tensor(trainset[0]).long(), torch.Tensor(trainset[1])\n",
    "ts_labels = (ts_labels > 5).float()\n",
    "dts = data.TensorDataset(ts, ts_labels)\n",
    "dlts = data.DataLoader(dts, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "vs, vs_labels = torch.Tensor(validset[0]).long(), torch.Tensor(validset[1])\n",
    "vs_labels = (vs_labels > 5).float()\n",
    "dvs = data.TensorDataset(vs, vs_labels)\n",
    "dlvs = data.DataLoader(dvs, batch_size=100)\n",
    "print(len(vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 2\n"
     ]
    }
   ],
   "source": [
    "#split_ratio = 0.9\n",
    "#split_idx = int(len(trainset) * split_ratio)\n",
    "#tidx = list(range(len(trainset)))\n",
    "#random.shuffle(tidx)\n",
    "#tidx, vidx = tidx[:split_idx], tidx[split_idx:]\n",
    "#ts, ts_labels = [trainset[tid] for tid in tidx], [train_labels[tid] for tid in tidx]\n",
    "#vs, vs_labels = [trainset[vid] for vid in vidx], [train_labels[vid] for vid in vidx]\n",
    "\n",
    "#ts, ts_labels = torch.Tensor(ts).long(), torch.Tensor(ts_labels)\n",
    "#ts_labels = (ts_labels > 5).float()\n",
    "#dts = data.TensorDataset(ts, ts_labels)\n",
    "#dlts = data.DataLoader(dts, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5000\n",
      "torch.Size([22500, 500])\n",
      "SingleHiddenNN (\n",
      "  (emb): Embedding(5001, 32)\n",
      "  (fc): Linear (16000 -> 100)\n",
      "  (relu): SELU\n",
      "  (dropout): Dropout (p = 0.7)\n",
      "  (out): Linear (100 -> 1)\n",
      "  (sigmoid): Sigmoid ()\n",
      ")\n",
      "epoch 1 had a loss of 180.21:\n",
      "epoch 2 had a loss of 149.41:\n",
      "epoch 3 had a loss of 157.26:\n",
      "epoch 4 had a loss of 136.89:\n",
      "epoch 5 had a loss of 146.05:\n",
      "epoch 6 had a loss of 128.16:\n",
      "correct: 1506, total: 2500\n",
      "validation accuracy: 60.24\n",
      "epoch 7 had a loss of 138.26:\n",
      "epoch 8 had a loss of 122.53:\n",
      "epoch 9 had a loss of 131.25:\n",
      "epoch 10 had a loss of 116.95:\n",
      "epoch 11 had a loss of 125.69:\n",
      "correct: 1515, total: 2500\n",
      "validation accuracy: 60.60\n",
      "epoch 12 had a loss of 113.37:\n",
      "epoch 13 had a loss of 120.07:\n",
      "epoch 14 had a loss of 106.46:\n",
      "epoch 15 had a loss of 116.02:\n",
      "epoch 16 had a loss of 102.44:\n",
      "correct: 1567, total: 2500\n",
      "validation accuracy: 62.68\n",
      "epoch 17 had a loss of 111.7:\n",
      "epoch 18 had a loss of 99.776:\n",
      "epoch 19 had a loss of 109.25:\n",
      "epoch 20 had a loss of 96.52:\n",
      "epoch 21 had a loss of 104.85:\n",
      "correct: 1563, total: 2500\n",
      "validation accuracy: 62.52\n",
      "epoch 22 had a loss of 91.543:\n",
      "epoch 23 had a loss of 100.93:\n",
      "epoch 24 had a loss of 89.977:\n",
      "epoch 25 had a loss of 97.779:\n",
      "epoch 26 had a loss of 85.79:\n",
      "correct: 1630, total: 2500\n",
      "validation accuracy: 65.20\n",
      "epoch 27 had a loss of 94.657:\n",
      "epoch 28 had a loss of 82.805:\n",
      "epoch 29 had a loss of 91.25:\n",
      "epoch 30 had a loss of 81.997:\n",
      "epoch 31 had a loss of 90.426:\n",
      "correct: 1589, total: 2500\n",
      "validation accuracy: 63.56\n",
      "epoch 32 had a loss of 78.93:\n",
      "epoch 33 had a loss of 86.228:\n",
      "epoch 34 had a loss of 76.29:\n",
      "epoch 35 had a loss of 83.203:\n",
      "epoch 36 had a loss of 74.013:\n",
      "correct: 1689, total: 2500\n",
      "validation accuracy: 67.56\n",
      "epoch 37 had a loss of 82.516:\n",
      "epoch 38 had a loss of 72.502:\n",
      "epoch 39 had a loss of 79.541:\n",
      "epoch 40 had a loss of 70.698:\n",
      "epoch 41 had a loss of 76.423:\n",
      "correct: 1676, total: 2500\n",
      "validation accuracy: 67.04\n",
      "epoch 42 had a loss of 66.121:\n",
      "epoch 43 had a loss of 74.163:\n",
      "epoch 44 had a loss of 65.6:\n",
      "epoch 45 had a loss of 72.702:\n",
      "epoch 46 had a loss of 63.273:\n",
      "correct: 1744, total: 2500\n",
      "validation accuracy: 69.76\n",
      "epoch 47 had a loss of 70.441:\n",
      "epoch 48 had a loss of 61.714:\n",
      "epoch 49 had a loss of 69.674:\n",
      "epoch 50 had a loss of 60.041:\n",
      "epoch 51 had a loss of 67.995:\n",
      "correct: 1672, total: 2500\n",
      "validation accuracy: 66.88\n",
      "epoch 52 had a loss of 58.486:\n",
      "epoch 53 had a loss of 67.985:\n",
      "epoch 54 had a loss of 56.784:\n",
      "epoch 55 had a loss of 65.629:\n",
      "epoch 56 had a loss of 55.778:\n",
      "correct: 1778, total: 2500\n",
      "validation accuracy: 71.12\n",
      "epoch 57 had a loss of 63.425:\n",
      "epoch 58 had a loss of 54.342:\n",
      "epoch 59 had a loss of 60.929:\n",
      "epoch 60 had a loss of 52.447:\n",
      "epoch 61 had a loss of 59.177:\n",
      "correct: 1784, total: 2500\n",
      "validation accuracy: 71.36\n",
      "epoch 62 had a loss of 50.707:\n",
      "epoch 63 had a loss of 59.645:\n",
      "epoch 64 had a loss of 48.444:\n",
      "epoch 65 had a loss of 58.692:\n",
      "epoch 66 had a loss of 47.309:\n",
      "correct: 1796, total: 2500\n",
      "validation accuracy: 71.84\n",
      "epoch 67 had a loss of 56.025:\n",
      "epoch 68 had a loss of 46.815:\n",
      "epoch 69 had a loss of 57.314:\n",
      "epoch 70 had a loss of 45.563:\n",
      "epoch 71 had a loss of 54.548:\n",
      "correct: 1807, total: 2500\n",
      "validation accuracy: 72.28\n",
      "epoch 72 had a loss of 43.947:\n",
      "epoch 73 had a loss of 51.221:\n",
      "epoch 74 had a loss of 43.44:\n",
      "epoch 75 had a loss of 50.027:\n",
      "epoch 76 had a loss of 41.055:\n",
      "correct: 1806, total: 2500\n",
      "validation accuracy: 72.24\n",
      "epoch 77 had a loss of 49.864:\n",
      "epoch 78 had a loss of 40.638:\n",
      "epoch 79 had a loss of 47.843:\n",
      "epoch 80 had a loss of 40.034:\n",
      "epoch 81 had a loss of 46.633:\n",
      "correct: 1817, total: 2500\n",
      "validation accuracy: 72.68\n",
      "epoch 82 had a loss of 38.564:\n",
      "epoch 83 had a loss of 45.391:\n",
      "epoch 84 had a loss of 38.921:\n",
      "epoch 85 had a loss of 44.739:\n",
      "epoch 86 had a loss of 36.371:\n",
      "correct: 1825, total: 2500\n",
      "validation accuracy: 73.00\n",
      "epoch 87 had a loss of 42.843:\n",
      "epoch 88 had a loss of 36.642:\n",
      "epoch 89 had a loss of 44.325:\n",
      "epoch 90 had a loss of 35.034:\n",
      "epoch 91 had a loss of 43.729:\n",
      "correct: 1835, total: 2500\n",
      "validation accuracy: 73.40\n",
      "epoch 92 had a loss of 34.83:\n",
      "epoch 93 had a loss of 43.054:\n",
      "epoch 94 had a loss of 34.262:\n",
      "epoch 95 had a loss of 42.408:\n",
      "epoch 96 had a loss of 33.244:\n",
      "correct: 1844, total: 2500\n",
      "validation accuracy: 73.76\n",
      "epoch 97 had a loss of 40.137:\n",
      "epoch 98 had a loss of 32.036:\n",
      "epoch 99 had a loss of 40.617:\n",
      "epoch 100 had a loss of 31.283:\n",
      "epoch 101 had a loss of 38.893:\n",
      "correct: 1818, total: 2500\n",
      "validation accuracy: 72.72\n",
      "epoch 102 had a loss of 30.514:\n",
      "epoch 103 had a loss of 36.414:\n",
      "epoch 104 had a loss of 29.846:\n",
      "epoch 105 had a loss of 35.484:\n",
      "epoch 106 had a loss of 28.688:\n",
      "correct: 1844, total: 2500\n",
      "validation accuracy: 73.76\n",
      "epoch 107 had a loss of 32.477:\n",
      "epoch 108 had a loss of 27.244:\n",
      "epoch 109 had a loss of 33.256:\n",
      "epoch 110 had a loss of 26.222:\n",
      "epoch 111 had a loss of 31.101:\n",
      "correct: 1846, total: 2500\n",
      "validation accuracy: 73.84\n",
      "epoch 112 had a loss of 26.721:\n",
      "epoch 113 had a loss of 30.268:\n",
      "epoch 114 had a loss of 25.618:\n",
      "epoch 115 had a loss of 28.931:\n",
      "epoch 116 had a loss of 25.284:\n",
      "correct: 1859, total: 2500\n",
      "validation accuracy: 74.36\n",
      "epoch 117 had a loss of 28.243:\n",
      "epoch 118 had a loss of 24.153:\n",
      "epoch 119 had a loss of 28.069:\n",
      "epoch 120 had a loss of 23.269:\n",
      "epoch 121 had a loss of 27.448:\n",
      "correct: 1866, total: 2500\n",
      "validation accuracy: 74.64\n",
      "epoch 122 had a loss of 22.092:\n",
      "epoch 123 had a loss of 25.823:\n",
      "epoch 124 had a loss of 22.316:\n",
      "epoch 125 had a loss of 26.363:\n",
      "epoch 126 had a loss of 22.562:\n",
      "correct: 1869, total: 2500\n",
      "validation accuracy: 74.76\n",
      "epoch 127 had a loss of 25.361:\n",
      "epoch 128 had a loss of 21.893:\n",
      "epoch 129 had a loss of 23.67:\n",
      "epoch 130 had a loss of 20.472:\n",
      "epoch 131 had a loss of 24.869:\n",
      "correct: 1872, total: 2500\n",
      "validation accuracy: 74.88\n",
      "epoch 132 had a loss of 20.084:\n",
      "epoch 133 had a loss of 23.902:\n",
      "epoch 134 had a loss of 20.17:\n",
      "epoch 135 had a loss of 24.072:\n",
      "epoch 136 had a loss of 19.705:\n",
      "correct: 1873, total: 2500\n",
      "validation accuracy: 74.92\n",
      "epoch 137 had a loss of 23.764:\n",
      "epoch 138 had a loss of 20.042:\n",
      "epoch 139 had a loss of 24.471:\n",
      "epoch 140 had a loss of 19.268:\n",
      "epoch 141 had a loss of 26.174:\n",
      "correct: 1865, total: 2500\n",
      "validation accuracy: 74.60\n",
      "epoch 142 had a loss of 19.303:\n",
      "epoch 143 had a loss of 26.392:\n",
      "epoch 144 had a loss of 20.878:\n",
      "epoch 145 had a loss of 29.359:\n",
      "epoch 146 had a loss of 19.566:\n",
      "correct: 1882, total: 2500\n",
      "validation accuracy: 75.28\n",
      "epoch 147 had a loss of 29.096:\n",
      "epoch 148 had a loss of 17.609:\n",
      "epoch 149 had a loss of 28.129:\n",
      "epoch 150 had a loss of 16.877:\n",
      "epoch 151 had a loss of 25.728:\n",
      "correct: 1887, total: 2500\n",
      "validation accuracy: 75.48\n",
      "epoch 152 had a loss of 16.436:\n",
      "epoch 153 had a loss of 24.018:\n",
      "epoch 154 had a loss of 15.716:\n",
      "epoch 155 had a loss of 20.792:\n",
      "epoch 156 had a loss of 14.76:\n",
      "correct: 1888, total: 2500\n",
      "validation accuracy: 75.52\n",
      "epoch 157 had a loss of 19.901:\n",
      "epoch 158 had a loss of 14.685:\n",
      "epoch 159 had a loss of 20.57:\n",
      "epoch 160 had a loss of 14.596:\n",
      "epoch 161 had a loss of 20.118:\n",
      "correct: 1909, total: 2500\n",
      "validation accuracy: 76.36\n",
      "epoch 162 had a loss of 14.506:\n",
      "epoch 163 had a loss of 18.156:\n",
      "epoch 164 had a loss of 14.234:\n",
      "epoch 165 had a loss of 18.269:\n",
      "epoch 166 had a loss of 14.057:\n",
      "correct: 1897, total: 2500\n",
      "validation accuracy: 75.88\n",
      "epoch 167 had a loss of 16.399:\n",
      "epoch 168 had a loss of 13.191:\n",
      "epoch 169 had a loss of 16.284:\n",
      "epoch 170 had a loss of 12.713:\n",
      "epoch 171 had a loss of 14.768:\n",
      "correct: 1897, total: 2500\n",
      "validation accuracy: 75.88\n",
      "epoch 172 had a loss of 12.85:\n",
      "epoch 173 had a loss of 14.618:\n",
      "epoch 174 had a loss of 12.6:\n",
      "epoch 175 had a loss of 13.754:\n",
      "epoch 176 had a loss of 12.1:\n",
      "correct: 1896, total: 2500\n",
      "validation accuracy: 75.84\n",
      "epoch 177 had a loss of 14.189:\n",
      "epoch 178 had a loss of 12.096:\n",
      "epoch 179 had a loss of 13.668:\n",
      "epoch 180 had a loss of 13.047:\n",
      "epoch 181 had a loss of 14.236:\n",
      "correct: 1884, total: 2500\n",
      "validation accuracy: 75.36\n",
      "epoch 182 had a loss of 12.84:\n",
      "epoch 183 had a loss of 12.927:\n",
      "epoch 184 had a loss of 12.742:\n",
      "epoch 185 had a loss of 12.622:\n",
      "epoch 186 had a loss of 13.217:\n",
      "correct: 1904, total: 2500\n",
      "validation accuracy: 76.16\n",
      "epoch 187 had a loss of 13.594:\n",
      "epoch 188 had a loss of 12.24:\n",
      "epoch 189 had a loss of 12.772:\n",
      "epoch 190 had a loss of 12.673:\n",
      "epoch 191 had a loss of 12.067:\n",
      "correct: 1835, total: 2500\n",
      "validation accuracy: 73.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192 had a loss of 13.577:\n",
      "epoch 193 had a loss of 13.533:\n",
      "epoch 194 had a loss of 13.713:\n",
      "epoch 195 had a loss of 12.667:\n",
      "epoch 196 had a loss of 11.576:\n",
      "correct: 1915, total: 2500\n",
      "validation accuracy: 76.60\n",
      "epoch 197 had a loss of 12.638:\n",
      "epoch 198 had a loss of 10.731:\n",
      "epoch 199 had a loss of 12.506:\n",
      "epoch 200 had a loss of 10.383:\n",
      "epoch 201 had a loss of 12.581:\n",
      "correct: 1844, total: 2500\n",
      "validation accuracy: 73.76\n",
      "epoch 202 had a loss of 12.099:\n",
      "epoch 203 had a loss of 13.259:\n",
      "epoch 204 had a loss of 10.19:\n",
      "epoch 205 had a loss of 14.359:\n",
      "epoch 206 had a loss of 10.284:\n",
      "correct: 1917, total: 2500\n",
      "validation accuracy: 76.68\n",
      "epoch 207 had a loss of 14.6:\n",
      "epoch 208 had a loss of 10.931:\n",
      "epoch 209 had a loss of 12.596:\n",
      "epoch 210 had a loss of 10.348:\n",
      "epoch 211 had a loss of 11.99:\n",
      "correct: 1856, total: 2500\n",
      "validation accuracy: 74.24\n",
      "epoch 212 had a loss of 11.241:\n",
      "epoch 213 had a loss of 11.915:\n",
      "epoch 214 had a loss of 11.312:\n",
      "epoch 215 had a loss of 10.298:\n",
      "epoch 216 had a loss of 10.769:\n",
      "correct: 1921, total: 2500\n",
      "validation accuracy: 76.84\n",
      "epoch 217 had a loss of 9.7846:\n",
      "epoch 218 had a loss of 10.23:\n",
      "epoch 219 had a loss of 8.9255:\n",
      "epoch 220 had a loss of 9.081:\n",
      "epoch 221 had a loss of 8.568:\n",
      "correct: 1853, total: 2500\n",
      "validation accuracy: 74.12\n",
      "epoch 222 had a loss of 8.9211:\n",
      "epoch 223 had a loss of 8.0079:\n",
      "epoch 224 had a loss of 9.1798:\n",
      "epoch 225 had a loss of 7.9771:\n",
      "epoch 226 had a loss of 8.3975:\n",
      "correct: 1921, total: 2500\n",
      "validation accuracy: 76.84\n",
      "epoch 227 had a loss of 9.0924:\n",
      "epoch 228 had a loss of 8.2583:\n",
      "epoch 229 had a loss of 8.2822:\n",
      "epoch 230 had a loss of 7.976:\n",
      "epoch 231 had a loss of 9.0271:\n",
      "correct: 1854, total: 2500\n",
      "validation accuracy: 74.16\n",
      "epoch 232 had a loss of 8.3784:\n",
      "epoch 233 had a loss of 8.3691:\n",
      "epoch 234 had a loss of 8.1224:\n",
      "epoch 235 had a loss of 8.0464:\n",
      "epoch 236 had a loss of 7.1277:\n",
      "correct: 1926, total: 2500\n",
      "validation accuracy: 77.04\n",
      "epoch 237 had a loss of 8.9603:\n",
      "epoch 238 had a loss of 8.8157:\n",
      "epoch 239 had a loss of 9.0398:\n",
      "epoch 240 had a loss of 6.0725:\n",
      "epoch 241 had a loss of 9.0863:\n",
      "correct: 1908, total: 2500\n",
      "validation accuracy: 76.32\n",
      "epoch 242 had a loss of 6.1797:\n",
      "epoch 243 had a loss of 8.3911:\n",
      "epoch 244 had a loss of 6.0233:\n",
      "epoch 245 had a loss of 7.594:\n",
      "epoch 246 had a loss of 5.2482:\n",
      "correct: 1922, total: 2500\n",
      "validation accuracy: 76.88\n",
      "epoch 247 had a loss of 8.3338:\n",
      "epoch 248 had a loss of 6.1232:\n",
      "epoch 249 had a loss of 8.2647:\n",
      "epoch 250 had a loss of 6.3322:\n"
     ]
    }
   ],
   "source": [
    "class SingleHiddenNN(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, embed_elems, batch_size):\n",
    "        super(SingleHiddenNN, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_elems = embed_elems\n",
    "        self.max_len = max_len\n",
    "        self.emb = nn.Embedding(self.vocab_size+1, self.embed_elems)\n",
    "        self.fc = nn.Linear(int(self.max_len * self.embed_elems), 100)\n",
    "        self.relu = nn.SELU()\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.out = nn.Linear(100, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        x = self.emb(input)\n",
    "        x = x.view(input.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "print(ts.min(), ts.max())\n",
    "print(ts.size())\n",
    "model = SingleHiddenNN(len(vocab), 500, 32, 100)\n",
    "print(model)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = []\n",
    "optimizer += [torch.optim.Adam(model.parameters(), lr=0.0001)]\n",
    "optimizer += [torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)]\n",
    "epochs = 250\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, (mb, tgts) in enumerate(dlts):\n",
    "        model.zero_grad()\n",
    "        mb, tgts = torch.autograd.Variable(mb), torch.autograd.Variable(tgts.float())\n",
    "        out = model(mb)\n",
    "        loss = criterion(out, tgts)\n",
    "        loss.backward()\n",
    "        opt_idx = epoch % 2\n",
    "        optimizer[opt_idx].step()\n",
    "        running_loss += loss.data[0]\n",
    "    print(\"epoch {} had a loss of {:.5}:\".format(epoch+1, running_loss))\n",
    "    if epoch > 0 and epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        for vmb, vtgts in dlvs:\n",
    "            vmb, vtgts = torch.autograd.Variable(vmb), torch.autograd.Variable(vtgts.float())\n",
    "            vout = model(vmb)\n",
    "            vpred = vout.round()\n",
    "            correct += (vpred == vtgts).data.sum()\n",
    "        print(\"correct: {}, total: {}\".format(correct, len(vs)))\n",
    "        print(\"validation accuracy: {:.2f}\".format(100.*correct/len(vs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 0.8076 2500\n",
      "\n",
      "    0     0\n",
      "    1     1\n",
      "    0     0\n",
      "    0     1\n",
      "    1     1\n",
      "    0     0\n",
      "    0     0\n",
      "    1     0\n",
      "    0     0\n",
      "    1     1\n",
      "    0     0\n",
      "    1     0\n",
      "    1     1\n",
      "    0     0\n",
      "    1     0\n",
      "    0     0\n",
      "    0     0\n",
      "    1     0\n",
      "    0     0\n",
      "    1     0\n",
      "    0     0\n",
      "    1     1\n",
      "    0     1\n",
      "    1     1\n",
      "    0     0\n",
      "    0     0\n",
      "    1     1\n",
      "    0     1\n",
      "    1     1\n",
      "    1     1\n",
      "    1     0\n",
      "    1     1\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     1\n",
      "    0     1\n",
      "    1     1\n",
      "    1     0\n",
      "    0     0\n",
      "    1     1\n",
      "    1     0\n",
      "    1     1\n",
      "    0     1\n",
      "    0     0\n",
      "    1     1\n",
      "    0     1\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    1     1\n",
      "    0     0\n",
      "    1     1\n",
      "    0     0\n",
      "    0     0\n",
      "    0     1\n",
      "    1     1\n",
      "    1     1\n",
      "    1     1\n",
      "    1     0\n",
      "    0     0\n",
      "    1     1\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    1     0\n",
      "    1     1\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    1     1\n",
      "    1     1\n",
      "    1     1\n",
      "    1     1\n",
      "    0     1\n",
      "    0     0\n",
      "    1     1\n",
      "    0     1\n",
      "    0     0\n",
      "    0     0\n",
      "    1     1\n",
      "    1     1\n",
      "    0     0\n",
      "    1     1\n",
      "    1     1\n",
      "    0     0\n",
      "    1     1\n",
      "    0     0\n",
      "    1     0\n",
      "    0     0\n",
      "    1     1\n",
      "    1     1\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    1     1\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, (mb, tgts) in enumerate(dlvs):\n",
    "    mb, tgts = torch.autograd.Variable(mb), torch.autograd.Variable(tgts.float())\n",
    "    out = model(mb)\n",
    "    pred = out.round()\n",
    "    correct += (pred == tgts).data.sum()\n",
    "print(correct, correct / len(vs), len(vs))\n",
    "print(torch.stack((pred.data, tgts.data), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_imdb_20170912.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torchtext.data as ttdata\n",
    "TEXT = ttdata.Field()\n",
    "LABEL = ttdata.Field(sequential=False)\n",
    "imdb_ds = torchtext.datasets.IMDB(\"/home/david/imdb_sentiment/data\", TEXT, LABEL)\n",
    "train_iter, test_iter = imdb_ds.iters(batch_size=4, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = imdb_ds.iters(batch_size=25, device=-1)\n",
    "for x in train_iter:\n",
    "    print(x.text, x.label.size())\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aae_supervised.py            notes.md\r\n",
      "\u001b[0m\u001b[01;34malgore\u001b[0m/                      numpy_reshape_test.ipynb\r\n",
      "AlGore_2009.sph              pad_test.py\r\n",
      "AlGore_2009.stm              \u001b[01;34mpcsnpny-20150204-mkj\u001b[0m/\r\n",
      "audio_rnn_basic.ipynb        \u001b[01;31mpcsnpny-20150204-mkj.tgz\u001b[0m\r\n",
      "\u001b[01;35mclipmin.png\u001b[0m                  \u001b[00;36mpiano2.mp3\u001b[0m\r\n",
      "CNN2RNN.ipynb                \u001b[00;36mpiano.mp3\u001b[0m\r\n",
      "collate_variable.py          \u001b[00;36mpiano_new.wav\u001b[0m\r\n",
      "\u001b[01;34mdata\u001b[0m/                        playground.ipynb\r\n",
      "\u001b[01;31mdata.zip\u001b[0m                     predict_audio.ipynb\r\n",
      "deepspeech1d.ipynb           Presentation.ipynb\r\n",
      "denoising_autoencoder.ipynb  prime_factors.py\r\n",
      "extract_mnist.py             pyaudio-test.py\r\n",
      "\u001b[00;36mfile2.wav\u001b[0m                    \u001b[01;34m__pycache__\u001b[0m/\r\n",
      "\u001b[00;36mfile.flac\u001b[0m                    pytorch_basics.ipynb\r\n",
      "\u001b[00;36mfile.mp3\u001b[0m                     PyTorch Embeddings Test.ipynb\r\n",
      "\u001b[00;36mfile.wav\u001b[0m                     pytorch_tutorial_classify_names.ipynb\r\n",
      "\u001b[01;34mfrancemusique\u001b[0m/               rnn_autoencoder.ipynb\r\n",
      "G729VAD.ipynb                \u001b[01;35mrnn_beispiel1.png\u001b[0m\r\n",
      "GRUAutoencoder.ipynb         \u001b[01;35mrnn_beispiel2.png\u001b[0m\r\n",
      "\u001b[00;36mhall√∂chen.wav\u001b[0m                \u001b[01;35mrnn_predictions_final.png\u001b[0m\r\n",
      "\u001b[01;32mhelloworld.py\u001b[0m*               \u001b[01;35mrnn_predictions.png\u001b[0m\r\n",
      "imdb_tokenize.ipynb          \u001b[01;35msmoother1.png\u001b[0m\r\n",
      "\u001b[01;35mkmeans1.png\u001b[0m                  \u001b[01;34msnipsdata\u001b[0m/\r\n",
      "\u001b[01;35mkmeans2.png\u001b[0m                  Snips_Report.ipynb\r\n",
      "label_smoothing.ipynb        \u001b[01;34mstarters\u001b[0m/\r\n",
      "levinson.py                  startup.sh\r\n",
      "librispeech_load_txts.ipynb  stm_sph_processing.ipynb\r\n",
      "librispeech.py               \u001b[01;35mtedlium1.png\u001b[0m\r\n",
      "loader.py                    \u001b[01;35mtedlium2.png\u001b[0m\r\n",
      "\u001b[01;34mmini_librispeech_dataset\u001b[0m/    tedlium_labels.ipynb\r\n",
      "\u001b[01;35mmlp_beispiel_noise1.png\u001b[0m      test_argparse.py\r\n",
      "\u001b[01;35mmlp_beispiel_noise2.png\u001b[0m      test_nltk.py\r\n",
      "\u001b[01;35mmlp_beispiel_nonoise1.png\u001b[0m    test_spacy.py\r\n",
      "\u001b[01;35mmlp_beispiel_nonoise2.png\u001b[0m    timeseries.ipynb\r\n",
      "\u001b[01;35mmlp_predictions_noise.png\u001b[0m    torchaudio\r\n",
      "\u001b[01;35mmlp_predictions.png\u001b[0m          torchaudio_vs_librosa.ipynb\r\n",
      "\u001b[01;34mMNIST\u001b[0m/                       VAD_labeling.ipynb\r\n",
      "model_20170912.pt            wavelet.ipynb\r\n",
      "\u001b[01;34mmodels\u001b[0m/                      yesno_torchaudio_playground.ipynb\r\n",
      "mu_law_companding.ipynb      zero2d_test.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
